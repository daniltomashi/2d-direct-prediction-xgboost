{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9250989,"sourceType":"datasetVersion","datasetId":5596719}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model, Input, applications\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow import keras\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nimport xgboost as xgb\n\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:25:41.348047Z","iopub.execute_input":"2024-09-04T20:25:41.348750Z","iopub.status.idle":"2024-09-04T20:26:08.404313Z","shell.execute_reply.started":"2024-09-04T20:25:41.348707Z","shell.execute_reply":"2024-09-04T20:26:08.403496Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"np.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:26:08.406489Z","iopub.execute_input":"2024-09-04T20:26:08.407423Z","iopub.status.idle":"2024-09-04T20:26:08.411830Z","shell.execute_reply.started":"2024-09-04T20:26:08.407366Z","shell.execute_reply":"2024-09-04T20:26:08.410899Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# batch_size = 8\nbatch_size = 16\n\nepochs = 60\n# epochs = 30","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:26:08.413111Z","iopub.execute_input":"2024-09-04T20:26:08.413390Z","iopub.status.idle":"2024-09-04T20:26:08.424905Z","shell.execute_reply.started":"2024-09-04T20:26:08.413352Z","shell.execute_reply":"2024-09-04T20:26:08.424201Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"main_directory = \"/kaggle/input/nutrition5k/\"","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:26:08.425898Z","iopub.execute_input":"2024-09-04T20:26:08.426196Z","iopub.status.idle":"2024-09-04T20:26:08.436472Z","shell.execute_reply.started":"2024-09-04T20:26:08.426166Z","shell.execute_reply":"2024-09-04T20:26:08.435663Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# folder and files names\nfolder = main_directory+\"Nutritions5k/realsense_overhead\"\ntypes_of_photo = [\"depth_color.png\", \"depth_raw.png\", \"rgb.png\"]\n\n# read files to understand which to put to train and which to test\nwith open(main_directory+\"Nutritions5k/dish_ids/splits/rgb_train_ids.txt\") as rgb_train_splits:\n    rgb_train_splits = [i.replace('\\n', '') for i in rgb_train_splits.readlines()]\n    \nwith open(main_directory+\"Nutritions5k/dish_ids/splits/rgb_test_ids.txt\") as rgb_test_splits:\n    rgb_test_splits = [i.replace('\\n', '') for i in rgb_test_splits.readlines()]\n    \n# take csv files which contains output values per dish\nreal_column_names = [\"dish_id\", \"total_calories\", \"total_mass\", \"total_fat\", \"total_carb\", \"total_protein\"]\ndish_metadata_cafe1 = pd.read_csv(main_directory+\"Nutritions5k/metadata/dish_metadata_cafe1.csv\", on_bad_lines='skip')\ndish_metadata_cafe2 = pd.read_csv(main_directory+\"Nutritions5k/metadata/dish_metadata_cafe2.csv\", on_bad_lines='skip')\ndish_metadata_cafe1 = dish_metadata_cafe1[dish_metadata_cafe1.columns[:6]]\ndish_metadata_cafe2 = dish_metadata_cafe2[dish_metadata_cafe2.columns[:6]]\n\n# columns it's actual values from the dataset, so put it inside of the DataFrame\n# and then change columns to actual names of columns\ndish_metadata_cafe1.loc[dish_metadata_cafe1.iloc[-1].name+1] = dish_metadata_cafe1.columns\ndish_metadata_cafe2.loc[dish_metadata_cafe2.iloc[-1].name+1] = dish_metadata_cafe2.columns\ndish_metadata_cafe1.columns = real_column_names\ndish_metadata_cafe2.columns = real_column_names\n    \n    \nrgb_imgs_train = []\nrgb_imgs_metadata_train = []\nrgb_imgs_test = []\nrgb_imgs_metadata_test = []\n\ndepth_imgs_train = []\ndepth_imgs_test = []\n\n# # parameters\nimage_size = (256,256)\n# image_size = (384,384)\n# image_size = (224,224)\n\n# go through all photos\nfor dish_folder in os.listdir(folder):\n    # read image and convert it to rgb\n    img = cv2.imread(folder+'/'+dish_folder+'/'+'rgb.png')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, image_size)\n    \n    depth_color = cv2.imread(folder+'/'+dish_folder+'/'+'depth_color.png')\n    depth_color = cv2.cvtColor(depth_color, cv2.COLOR_BGR2RGB)\n    depth_color = cv2.resize(depth_color, image_size)\n    \n    # take nutrition values and mass of food\n    if dish_folder in dish_metadata_cafe1[\"dish_id\"].values:\n        dish_metadata = dish_metadata_cafe1[dish_metadata_cafe1[\"dish_id\"] == dish_folder].values[0][1:]\n    elif dish_folder in dish_metadata_cafe2[\"dish_id\"].values:\n        dish_metadata = dish_metadata_cafe2[dish_metadata_cafe2[\"dish_id\"] == dish_folder].values[0][1:]\n    else:\n        continue\n    \n    if dish_folder in rgb_train_splits:\n        rgb_imgs_train.append(img)\n        depth_imgs_train.append(depth_color)\n        rgb_imgs_metadata_train.append(dish_metadata)\n    elif dish_folder in rgb_test_splits:\n        rgb_imgs_test.append(img)\n        depth_imgs_test.append(depth_color)\n        rgb_imgs_metadata_test.append(dish_metadata)\n    \n    \nrgb_imgs_metadata_train = np.array([i.astype(np.float32) for i in rgb_imgs_metadata_train])\nrgb_imgs_metadata_test = np.array([i.astype(np.float32) for i in rgb_imgs_metadata_test])\n\nrgb_imgs_train = np.array(rgb_imgs_train)\nrgb_imgs_test = np.array(rgb_imgs_test)\n\ndepth_imgs_train = np.array(depth_imgs_train)\ndepth_imgs_test = np.array(depth_imgs_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:26:08.439510Z","iopub.execute_input":"2024-09-04T20:26:08.439797Z","iopub.status.idle":"2024-09-04T20:29:06.150510Z","shell.execute_reply.started":"2024-09-04T20:26:08.439762Z","shell.execute_reply":"2024-09-04T20:29:06.149624Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(\"Train max -->\", rgb_imgs_metadata_train.max(axis=0))\nprint(\"Test max -->\", rgb_imgs_metadata_test.max(axis=0))\nprint()\nprint(\"Train min -->\", rgb_imgs_metadata_train.min(axis=0))\nprint(\"Test min -->\", rgb_imgs_metadata_test.min(axis=0))\nprint()\nprint(\"Train mean -->\", rgb_imgs_metadata_train.mean(axis=0))\nprint(\"Test mean -->\", rgb_imgs_metadata_test.mean(axis=0))\nprint()\nprint(\"Train median -->\", np.median(rgb_imgs_metadata_train, axis=0))\nprint(\"Test median -->\", np.median(rgb_imgs_metadata_test, axis=0))","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:29:06.151627Z","iopub.execute_input":"2024-09-04T20:29:06.151923Z","iopub.status.idle":"2024-09-04T20:29:06.164900Z","shell.execute_reply.started":"2024-09-04T20:29:06.151891Z","shell.execute_reply":"2024-09-04T20:29:06.163978Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Train max --> [3943.3252   3051.        106.343     844.5686    120.443954]\nTest max --> [1050.5111  871.       84.153    85.81     84.645 ]\n\nTrain min --> [0. 5. 0. 0. 0.]\nTest min --> [0. 1. 0. 0. 0.]\n\nTrain mean --> [229.09233  199.97179   11.444165  18.087877  15.380763]\nTest mean --> [232.27643  182.58667   11.479245  19.038528  14.982078]\n\nTrain median --> [176.14001  161.         7.169495  13.860001   8.698   ]\nTest median --> [185.83298   143.          6.9696765  14.597746    8.567883 ]\n","output_type":"stream"}]},{"cell_type":"code","source":"# outliers_upper = np.where(rgb_imgs_metadata_train[:, 0] >= np.percentile(rgb_imgs_metadata_train[:, 0], 99))[0]\n# outliers_lower = np.where(rgb_imgs_metadata_train[:, 0] <= np.percentile(rgb_imgs_metadata_train[:, 0], 1))[0]\n\n# indexes_without_outliers = [i for i in range(len(rgb_imgs_metadata_train)) if i not in outliers_upper.tolist()+outliers_lower.tolist()]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:29:06.166154Z","iopub.execute_input":"2024-09-04T20:29:06.166455Z","iopub.status.idle":"2024-09-04T20:29:06.182025Z","shell.execute_reply.started":"2024-09-04T20:29:06.166423Z","shell.execute_reply":"2024-09-04T20:29:06.181328Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # worser results\n# rgb_imgs_train, depth_imgs_train, rgb_imgs_metadata_train = rgb_imgs_train[indexes_without_outliers],\\\n#                                                             depth_imgs_train[indexes_without_outliers],\\\n#                                                             rgb_imgs_metadata_train[indexes_without_outliers]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:29:06.183108Z","iopub.execute_input":"2024-09-04T20:29:06.183451Z","iopub.status.idle":"2024-09-04T20:29:06.196824Z","shell.execute_reply.started":"2024-09-04T20:29:06.183410Z","shell.execute_reply":"2024-09-04T20:29:06.196111Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation and division dataset to train, validation","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\", seed=42),\n#     tf.keras.layers.RandomRotation(0.2, seed=42),\n#     tf.keras.layers.RandomZoom(0.1, seed=42)\n    tf.keras.layers.RandomRotation(0.1, seed=42),\n    tf.keras.layers.RandomZoom(0.05, seed=42),\n    tf.keras.layers.RandomContrast(0.1, seed=42),\n    tf.keras.layers.RandomBrightness(0.1, seed=42),\n    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1)\n])\n\n\ndef augment_image(rgb_img, depth_img, threshold=0.5):\n    image = np.concatenate([rgb_img, depth_img], axis=-1)\n    # Randomly choose to apply augmentation based on the defined probability\n    if tf.random.uniform([]) < threshold:\n        image = data_augmentation(image)\n        \n    augmented_rgb = image[..., :3]  # First three channels for RGB\n    augmented_depth = image[..., 3:]  # Last channel for depth\n    \n    return augmented_rgb, augmented_depth","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:29:06.197899Z","iopub.execute_input":"2024-09-04T20:29:06.198252Z","iopub.status.idle":"2024-09-04T20:29:07.139390Z","shell.execute_reply.started":"2024-09-04T20:29:06.198212Z","shell.execute_reply":"2024-09-04T20:29:07.138522Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# divide train to train and validation\ntrain_indexes = [i for i in range(len(rgb_imgs_train))]\nvalidation_len = int(len(train_indexes) * 0.1)\n\nvalidation_indexes = np.random.choice(train_indexes, validation_len)\ntrain_indexes = [i for i in train_indexes if i not in validation_indexes]\n\n# take data only for validation\nrgb_imgs_validation = rgb_imgs_train[validation_indexes]\ndepth_imgs_validation = depth_imgs_train[validation_indexes]\nrgb_imgs_metadata_validation = rgb_imgs_metadata_train[validation_indexes]\n\n# take data only for train\nrgb_imgs_train = rgb_imgs_train[train_indexes]\ndepth_imgs_train = depth_imgs_train[train_indexes]\nrgb_imgs_metadata_train = rgb_imgs_metadata_train[train_indexes]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:29:07.140485Z","iopub.execute_input":"2024-09-04T20:29:07.140779Z","iopub.status.idle":"2024-09-04T20:29:07.434143Z","shell.execute_reply.started":"2024-09-04T20:29:07.140747Z","shell.execute_reply":"2024-09-04T20:29:07.433332Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"augmented_imgs = np.array([augment_image(i, j) for i, j in zip(rgb_imgs_train, depth_imgs_train)]) / 255\nrgb_imgs_train, depth_imgs_train = augmented_imgs[:, 0], augmented_imgs[:, 1]\n\n# rgb_imgs_train, depth_imgs_train = rgb_imgs_train / 255, depth_imgs_train / 255\n\nrgb_imgs_test = rgb_imgs_test / 255\nrgb_imgs_validation = rgb_imgs_validation / 255\n\n\ndel augmented_imgs","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:29:07.435370Z","iopub.execute_input":"2024-09-04T20:29:07.435742Z","iopub.status.idle":"2024-09-04T20:30:01.773182Z","shell.execute_reply.started":"2024-09-04T20:29:07.435701Z","shell.execute_reply":"2024-09-04T20:30:01.772332Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"depth_imgs_validation = depth_imgs_validation / 255\ndepth_imgs_test = depth_imgs_test / 255","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:01.774370Z","iopub.execute_input":"2024-09-04T20:30:01.774709Z","iopub.status.idle":"2024-09-04T20:30:02.059331Z","shell.execute_reply.started":"2024-09-04T20:30:01.774673Z","shell.execute_reply":"2024-09-04T20:30:02.058289Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"if image_size == (384,384):\n    indexes = [i for i in range(len(rgb_imgs_train))]\n    np.random.shuffle(indexes)\n    indexes = indexes[:1400]\n    rgb_imgs_train = rgb_imgs_train[indexes]\n    depth_imgs_train = depth_imgs_train[indexes]\n    rgb_imgs_metadata_train = rgb_imgs_metadata_train[indexes]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.060539Z","iopub.execute_input":"2024-09-04T20:30:02.060832Z","iopub.status.idle":"2024-09-04T20:30:02.066565Z","shell.execute_reply.started":"2024-09-04T20:30:02.060802Z","shell.execute_reply":"2024-09-04T20:30:02.065621Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Model without depth","metadata":{}},{"cell_type":"code","source":"def get_callbacks():\n    early_stopping = EarlyStopping(\n        monitor='val_loss',       # Monitor validation loss\n        patience=5,               # Number of epochs to wait before stopping\n        min_delta=0.01,           # Minimum change to qualify as improvement\n        mode='min',               # Stop when the metric is minimizing (val_loss is decreasing)\n        restore_best_weights=True # Restore model weights from the epoch with the best value\n    )\n    return [early_stopping]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.071291Z","iopub.execute_input":"2024-09-04T20:30:02.071654Z","iopub.status.idle":"2024-09-04T20:30:02.080196Z","shell.execute_reply.started":"2024-09-04T20:30:02.071623Z","shell.execute_reply":"2024-09-04T20:30:02.079371Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# \"total_calories\", \"total_mass\", \"total_fat\", \"total_carb\", \"total_protein\"\ndef custom_multitask_loss(y_true, y_pred):\n    y_true_macro, y_true_cal, y_true_weight = y_true[:, 2:], y_true[:, 0], y_true[:, 1]\n    y_pred_macro, y_pred_cal, y_pred_weight = y_pred[:, 2:], y_pred[:, 0], y_pred[:, 1]\n\n    # lm\n    macro_loss = tf.reduce_mean(tf.abs(y_pred_macro - y_true_macro), axis=1)\n    # lc\n    calorie_loss = tf.abs(y_pred_cal - y_true_cal)\n    # lw\n    weight_loss = tf.abs(y_pred_weight - y_true_weight)\n\n#     total_loss = macro_loss + calorie_loss + weight_loss\n    total_loss = tf.reduce_mean(macro_loss + calorie_loss + weight_loss)\n\n    \n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.081219Z","iopub.execute_input":"2024-09-04T20:30:02.081493Z","iopub.status.idle":"2024-09-04T20:30:02.094513Z","shell.execute_reply.started":"2024-09-04T20:30:02.081463Z","shell.execute_reply":"2024-09-04T20:30:02.093633Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def geometric_mean_loss(y_true, y_pred):\n    # Split ground truth and predicted values into separate tensors\n    y_cal_true, y_mass_true, y_fat_true, y_carb_true, y_protein_true = tf.split(y_true, num_or_size_splits=5, axis=-1)\n    y_cal_pred, y_mass_pred, y_fat_pred, y_carb_pred, y_protein_pred = tf.split(y_pred, num_or_size_splits=5, axis=-1)\n\n    # Calculate L1 losses for each subtask\n    L_cal = tf.reduce_mean(tf.abs(y_cal_true - y_cal_pred))\n    L_mass = tf.reduce_mean(tf.abs(y_mass_true - y_mass_pred))\n    L_fat = tf.reduce_mean(tf.abs(y_fat_true - y_fat_pred))\n    L_carb = tf.reduce_mean(tf.abs(y_carb_true - y_carb_pred))\n    L_protein = tf.reduce_mean(tf.abs(y_protein_true - y_protein_pred))\n\n    # Combine losses using geometric mean\n    L_total = (L_cal * L_mass * L_fat * L_carb * L_protein) ** (1/5)\n\n    return L_total","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.095555Z","iopub.execute_input":"2024-09-04T20:30:02.095803Z","iopub.status.idle":"2024-09-04T20:30:02.107588Z","shell.execute_reply.started":"2024-09-04T20:30:02.095774Z","shell.execute_reply":"2024-09-04T20:30:02.106744Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# NOTE: delete after test\nclass ChannelAttention(layers.Layer):\n    def __init__(self, ratio=8, **kwargs):\n        super(ChannelAttention, self).__init__(**kwargs)\n        self.ratio = ratio\n    \n    def build(self, input_shape):\n        channel = input_shape[-1]\n        self.shared_dense_one = layers.Dense(channel // self.ratio, activation='relu', use_bias=True)\n        self.shared_dense_two = layers.Dense(channel, use_bias=True)\n    \n    def call(self, input_feature):\n        avg_pool = layers.GlobalAveragePooling2D()(input_feature)\n        avg_pool = layers.Reshape((1, 1, input_feature.shape[-1]))(avg_pool)\n        avg_pool = self.shared_dense_one(avg_pool)\n        avg_pool = self.shared_dense_two(avg_pool)\n        \n        max_pool = layers.GlobalMaxPooling2D()(input_feature)\n        max_pool = layers.Reshape((1, 1, input_feature.shape[-1]))(max_pool)\n        max_pool = self.shared_dense_one(max_pool)\n        max_pool = self.shared_dense_two(max_pool)\n        \n        cbam_feature = layers.Add()([avg_pool, max_pool])\n        cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n        \n        return layers.Multiply()([input_feature, cbam_feature])\n\n# Custom Layer for Spatial Attention\nclass SpatialAttention(layers.Layer):\n    def __init__(self, **kwargs):\n        super(SpatialAttention, self).__init__(**kwargs)\n        self.conv = None\n    \n    def build(self, input_shape):\n        self.conv = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding='same', activation='sigmoid', use_bias=False)\n    \n    def call(self, input_feature):\n        avg_pool = tf.reduce_mean(input_feature, axis=-1, keepdims=True)\n        max_pool = tf.reduce_max(input_feature, axis=-1, keepdims=True)\n        concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n        \n        cbam_feature = self.conv(concat)\n        \n        return layers.Multiply()([input_feature, cbam_feature])\n\n# CBAM Block using the Custom Layers\ndef cbam_block(cbam_input, ratio=8):\n    x = ChannelAttention(ratio=ratio)(cbam_input)\n    x = SpatialAttention()(x)\n    return x\n# NOTE: delete after test","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.108648Z","iopub.execute_input":"2024-09-04T20:30:02.108919Z","iopub.status.idle":"2024-09-04T20:30:02.127010Z","shell.execute_reply.started":"2024-09-04T20:30:02.108890Z","shell.execute_reply":"2024-09-04T20:30:02.126288Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def nutrition5k(image_size=(256,256,3), version=\"v2\", n_outputs=5, loss=\"custom\", original=False):\n    # Build the model\n    inputs = tf.keras.Input(shape=image_size)\n    \n    if version == \"v2\":\n        # Load Inception V3 as the feature extractor, excluding the top layers\n        model = applications.InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=inputs, input_shape=image_size)\n        model.trainable = False\n        x = model.get_layer(model.layers[-1].name).output\n       \n    elif version == \"v3\":\n        model = applications.InceptionV3(weights='imagenet', include_top=False, input_tensor=inputs, input_shape=image_size)\n        model.trainable = False\n        x = model.get_layer(\"mixed5\").output\n    else:\n        raise TypeError(\"This version does not exist, please choose between 'v2', 'v3'\")\n\n    if not original:\n        x = cbam_block(x)\n        x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n        x = layers.GlobalAveragePooling2D(name=\"feature_extractor\")(x)\n        \n        x_1 = layers.Dense(512)(x)\n        x_2 = layers.Dense(512)(x)\n        x_3 = layers.Dense(512)(x)\n        x_4 = layers.Dense(512)(x)\n\n        x = layers.Add()([x_1, x_2, x_3, x_4])\n\n        \n    if original:\n        # Apply [3, 3] average pooling with stride 2 and valid padding\n        x = layers.AveragePooling2D(pool_size=(3, 3), strides=2, padding='valid')(x)\n        x = layers.Flatten()(x)\n\n    # Fully connected layers\n    x = layers.Dense(4096)(x)\n    x = layers.Dense(4096)(x)\n    x = layers.Dense(4096)(x)\n    \n    \n    outputs = layers.Dense(n_outputs)(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    if original:\n        # Compile the model with a suitable loss function for regression tasks\n        optimizer = keras.optimizers.RMSprop(learning_rate=1e-4,\n                                             momentum=0.9,\n                                             epsilon=1.0,\n                                             weight_decay=0.9)\n    else:\n        optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n    \n    if loss == \"custom\":\n        loss_func = custom_multitask_loss\n    elif loss == \"geometric\":\n        loss_func = geometric_mean_loss\n    elif loss == \"mse\":\n        loss_func = \"mean_squared_error\"\n    else:\n        loss_func = \"mean_absolute_error\"\n\n    model.compile(optimizer=optimizer, loss=loss_func, metrics=[\"mae\"])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.128103Z","iopub.execute_input":"2024-09-04T20:30:02.128389Z","iopub.status.idle":"2024-09-04T20:30:02.144965Z","shell.execute_reply.started":"2024-09-04T20:30:02.128360Z","shell.execute_reply":"2024-09-04T20:30:02.144035Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def test_model(model, x, y_real):\n    test_predicted = model.predict(x)\n\n    test_errors = np.abs(test_predicted - y_real)\n\n    for val_name, val in zip(real_column_names[1:], np.mean(test_errors, axis=0)):\n        print(\"MAE Mean for\", val_name, '-->', val)\n        \n    print(\"Total MAE -->\", np.mean(test_errors))","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.146059Z","iopub.execute_input":"2024-09-04T20:30:02.146352Z","iopub.status.idle":"2024-09-04T20:30:02.162620Z","shell.execute_reply.started":"2024-09-04T20:30:02.146322Z","shell.execute_reply":"2024-09-04T20:30:02.161789Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def xgboost_test(model, inputs, outputs):\n    rgb_imgs_train, rgb_imgs_validation, rgb_imgs_test = inputs\n    rgb_imgs_metadata_train, rgb_imgs_metadata_validation, rgb_imgs_metadata_test = outputs\n\n    feature_extractor = Model(inputs=model.input, outputs=model.get_layer(\"feature_extractor\").output)\n\n    # Extract features from training data\n    train_features = feature_extractor.predict(rgb_imgs_train)\n    val_features = feature_extractor.predict(rgb_imgs_validation)\n    test_features = feature_extractor.predict(rgb_imgs_test)\n\n    xgboost_params = {\n                'objective': 'reg:squarederror',  # Use 'reg:squarederror' for regression tasks\n                'n_estimators': 50,               # Start with a moderate number of trees\n                'max_depth': 6,                   # Maximum depth of a tree\n                'learning_rate': 0.1,             # Step size shrinkage\n                'subsample': 0.8,                 # Subsample ratio of the training instance\n                'colsample_bytree': 0.8,          # Subsample ratio of columns when constructing each tree\n                'gamma': 0,                       # Minimum loss reduction required to make a further partition\n                'alpha': 0,                       # L1 regularization term on weights\n                'lambda': 1,                      # L2 regularization term on weights\n                'random_state': 42                # For reproducibility\n    }\n\n    xgb_model = xgb.XGBRegressor(**xgboost_params)\n\n    # Train the Random Forest regressor using extracted features\n    xgb_model.fit(train_features, rgb_imgs_metadata_train)\n\n    # Predict on validation features\n    y_pred = xgb_model.predict(val_features)\n\n    # Calculate Mean Absolute Error\n    mae = mean_absolute_error(rgb_imgs_metadata_validation, y_pred)\n    print(f'Validation Mean Absolute Error of: {mae}')\n    \n    test_model(xgb_model, test_features, rgb_imgs_metadata_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.163979Z","iopub.execute_input":"2024-09-04T20:30:02.164489Z","iopub.status.idle":"2024-09-04T20:30:02.176327Z","shell.execute_reply.started":"2024-09-04T20:30:02.164442Z","shell.execute_reply":"2024-09-04T20:30:02.175625Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# model = nutrition5k(image_size=image_size+(3,), version=\"efficientnet\", loss=\"geometric\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.177454Z","iopub.execute_input":"2024-09-04T20:30:02.177809Z","iopub.status.idle":"2024-09-04T20:30:02.192740Z","shell.execute_reply.started":"2024-09-04T20:30:02.177779Z","shell.execute_reply":"2024-09-04T20:30:02.191987Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n#                     validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation))","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.193771Z","iopub.execute_input":"2024-09-04T20:30:02.194044Z","iopub.status.idle":"2024-09-04T20:30:02.216821Z","shell.execute_reply.started":"2024-09-04T20:30:02.194014Z","shell.execute_reply":"2024-09-04T20:30:02.215971Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# test_predicted = model.predict(rgb_imgs_test)\n\n# test_errors = np.abs(test_predicted - rgb_imgs_metadata_test)\n\n# for val_name, val in zip(real_column_names[1:], np.mean(test_errors, axis=0)):\n#     print(\"MAE Mean for\", val_name, '-->', val)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.218168Z","iopub.execute_input":"2024-09-04T20:30:02.218999Z","iopub.status.idle":"2024-09-04T20:30:02.226722Z","shell.execute_reply.started":"2024-09-04T20:30:02.218956Z","shell.execute_reply":"2024-09-04T20:30:02.225891Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Original method","metadata":{}},{"cell_type":"code","source":"model = nutrition5k(image_size=image_size+(3,), version=\"v3\", loss=\"geometric\", original=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:02.227886Z","iopub.execute_input":"2024-09-04T20:30:02.228193Z","iopub.status.idle":"2024-09-04T20:30:05.192781Z","shell.execute_reply.started":"2024-09-04T20:30:02.228162Z","shell.execute_reply":"2024-09-04T20:30:05.191988Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\nhistory = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n                    validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:30:05.194142Z","iopub.execute_input":"2024-09-04T20:30:05.194794Z","iopub.status.idle":"2024-09-04T20:34:40.676771Z","shell.execute_reply.started":"2024-09-04T20:30:05.194741Z","shell.execute_reply":"2024-09-04T20:34:40.675694Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1725481813.993304     107 service.cc:145] XLA service 0x5ae59b18ce90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1725481813.993366     107 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1725481813.993371     107 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/139\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 46.5647 - mae: 100.5238","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1725481821.277925     107 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 146ms/step - loss: 35.5905 - mae: 89.5624 - val_loss: 31.2327 - val_mae: 78.4133\nEpoch 2/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - loss: 28.4275 - mae: 69.1316 - val_loss: 27.2249 - val_mae: 59.6656\nEpoch 3/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - loss: 25.6026 - mae: 57.0992 - val_loss: 25.3877 - val_mae: 55.8062\nEpoch 4/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - loss: 23.7892 - mae: 53.9529 - val_loss: 24.3237 - val_mae: 53.0404\nEpoch 5/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - loss: 23.2920 - mae: 51.5532 - val_loss: 23.7381 - val_mae: 50.0684\nEpoch 6/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - loss: 21.9018 - mae: 48.2976 - val_loss: 22.6517 - val_mae: 46.5611\nEpoch 7/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - loss: 20.9632 - mae: 44.9339 - val_loss: 21.5315 - val_mae: 43.6658\nEpoch 8/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 19.6152 - mae: 41.6943 - val_loss: 22.3757 - val_mae: 42.3676\nEpoch 9/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 19.3525 - mae: 39.8150 - val_loss: 20.6142 - val_mae: 40.6051\nEpoch 10/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 18.5410 - mae: 38.0680 - val_loss: 20.3473 - val_mae: 39.6820\nEpoch 11/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - loss: 18.2299 - mae: 37.0307 - val_loss: 19.9985 - val_mae: 38.9485\nEpoch 12/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 17.1841 - mae: 35.7546 - val_loss: 19.8344 - val_mae: 38.3094\nEpoch 13/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 17.4506 - mae: 35.3829 - val_loss: 19.4377 - val_mae: 37.7503\nEpoch 14/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 17.4874 - mae: 35.1188 - val_loss: 20.4251 - val_mae: 37.8619\nEpoch 15/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - loss: 16.3853 - mae: 33.7243 - val_loss: 19.3498 - val_mae: 37.0810\nEpoch 16/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 16.4670 - mae: 33.2601 - val_loss: 20.2416 - val_mae: 37.9474\nEpoch 17/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 16.0691 - mae: 32.7030 - val_loss: 19.8897 - val_mae: 37.0210\nEpoch 18/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 15.5905 - mae: 32.2728 - val_loss: 18.8068 - val_mae: 36.7281\nEpoch 19/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - loss: 15.4524 - mae: 31.9657 - val_loss: 18.5171 - val_mae: 35.8854\nEpoch 20/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 15.8255 - mae: 32.0389 - val_loss: 19.1961 - val_mae: 36.6906\nEpoch 21/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 16.2107 - mae: 31.9895 - val_loss: 21.1764 - val_mae: 37.0568\nEpoch 22/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 15.2030 - mae: 31.3220 - val_loss: 18.3568 - val_mae: 35.4669\nEpoch 23/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 14.9034 - mae: 30.8731 - val_loss: 19.7473 - val_mae: 35.9793\nEpoch 24/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 15.3673 - mae: 31.4073 - val_loss: 18.1951 - val_mae: 35.2731\nEpoch 25/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 14.4072 - mae: 30.2619 - val_loss: 19.1480 - val_mae: 35.5669\nEpoch 26/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 14.6071 - mae: 30.6176 - val_loss: 19.0167 - val_mae: 35.8525\nEpoch 27/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 14.1532 - mae: 29.9792 - val_loss: 20.1286 - val_mae: 36.8127\nEpoch 28/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 14.6262 - mae: 29.8111 - val_loss: 18.3012 - val_mae: 35.6639\nEpoch 29/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 13.8228 - mae: 29.4208 - val_loss: 19.4942 - val_mae: 35.3795\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(model, rgb_imgs_test, rgb_imgs_metadata_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:34:40.684150Z","iopub.execute_input":"2024-09-04T20:34:40.684572Z","iopub.status.idle":"2024-09-04T20:34:53.574119Z","shell.execute_reply.started":"2024-09-04T20:34:40.684536Z","shell.execute_reply":"2024-09-04T20:34:53.573145Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 343ms/step\nMAE Mean for total_calories --> 95.43458\nMAE Mean for total_mass --> 54.10184\nMAE Mean for total_fat --> 6.873353\nMAE Mean for total_carb --> 8.130579\nMAE Mean for total_protein --> 8.1826515\nTotal MAE --> 34.544605\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Modified method","metadata":{}},{"cell_type":"code","source":"# mse right now running\nmodel = nutrition5k(image_size=image_size+(3,), version=\"v3\", loss=\"geometric\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:34:53.575287Z","iopub.execute_input":"2024-09-04T20:34:53.575617Z","iopub.status.idle":"2024-09-04T20:34:55.850756Z","shell.execute_reply.started":"2024-09-04T20:34:53.575583Z","shell.execute_reply":"2024-09-04T20:34:55.849996Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\nhistory = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n                    validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:34:55.851901Z","iopub.execute_input":"2024-09-04T20:34:55.852234Z","iopub.status.idle":"2024-09-04T20:37:14.752926Z","shell.execute_reply.started":"2024-09-04T20:34:55.852185Z","shell.execute_reply":"2024-09-04T20:37:14.751856Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1725482108.618124     701 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_24', 36 bytes spill stores, 28 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 160ms/step - loss: 33.2733 - mae: 81.3726 - val_loss: 23.3158 - val_mae: 40.1044\nEpoch 2/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 21.4933 - mae: 38.5806 - val_loss: 21.6233 - val_mae: 37.5447\nEpoch 3/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 19.4730 - mae: 35.6824 - val_loss: 19.0353 - val_mae: 35.4190\nEpoch 4/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 17.6811 - mae: 32.9818 - val_loss: 17.9714 - val_mae: 33.6163\nEpoch 5/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 16.5782 - mae: 31.0487 - val_loss: 19.1419 - val_mae: 37.7152\nEpoch 6/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 16.3685 - mae: 30.1677 - val_loss: 16.5385 - val_mae: 30.6327\nEpoch 7/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 15.0289 - mae: 27.4370 - val_loss: 16.1888 - val_mae: 29.8732\nEpoch 8/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 13.7132 - mae: 25.2852 - val_loss: 15.3090 - val_mae: 28.9663\nEpoch 9/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 13.0884 - mae: 24.1361 - val_loss: 15.8302 - val_mae: 28.3862\nEpoch 10/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 12.7045 - mae: 23.4877 - val_loss: 15.8213 - val_mae: 27.9307\nEpoch 11/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 12.1657 - mae: 22.1586 - val_loss: 15.5340 - val_mae: 27.3562\nEpoch 12/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 11.6217 - mae: 21.0105 - val_loss: 14.1326 - val_mae: 25.9133\nEpoch 13/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 11.3380 - mae: 20.6796 - val_loss: 15.2270 - val_mae: 26.8666\nEpoch 14/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 10.7491 - mae: 19.2524 - val_loss: 15.5311 - val_mae: 27.2565\nEpoch 15/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 10.4732 - mae: 19.3215 - val_loss: 15.8607 - val_mae: 29.2268\nEpoch 16/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 12.3644 - mae: 22.5914 - val_loss: 14.9611 - val_mae: 28.4782\nEpoch 17/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 10.1314 - mae: 18.7926 - val_loss: 15.9665 - val_mae: 26.6213\n","output_type":"stream"}]},{"cell_type":"code","source":"xgboost_test(model, inputs=[rgb_imgs_train, rgb_imgs_validation, rgb_imgs_test],\n                          outputs=[rgb_imgs_metadata_train, rgb_imgs_metadata_validation, rgb_imgs_metadata_test])\n\n# With last 4096 \n# MAE Mean for total_calories --> 79.45708275180662\n# MAE Mean for total_mass --> 53.23186666666662\n# MAE Mean for total_fat --> 6.384834461182731\n# MAE Mean for total_carb --> 8.153495717423656\n# MAE Mean for total_protein --> 7.8782022629967985","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:37:14.754721Z","iopub.execute_input":"2024-09-04T20:37:14.755233Z","iopub.status.idle":"2024-09-04T20:37:41.522292Z","shell.execute_reply.started":"2024-09-04T20:37:14.755188Z","shell.execute_reply":"2024-09-04T20:37:41.521472Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step\nValidation Mean Absolute Error of: 26.658559799194336\nMAE Mean for total_calories --> 73.518524\nMAE Mean for total_mass --> 46.35223\nMAE Mean for total_fat --> 5.189673\nMAE Mean for total_carb --> 7.0847692\nMAE Mean for total_protein --> 6.931301\nTotal MAE --> 27.815296\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(model, rgb_imgs_test, rgb_imgs_metadata_test)\n\n# With last 4096\n# MAE Mean for total_calories --> 96.324486\n# MAE Mean for total_mass --> 55.977676\n# MAE Mean for total_fat --> 8.200258\n# MAE Mean for total_carb --> 8.190553\n# MAE Mean for total_protein --> 9.116547","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:37:41.525658Z","iopub.execute_input":"2024-09-04T20:37:41.526353Z","iopub.status.idle":"2024-09-04T20:37:53.178091Z","shell.execute_reply.started":"2024-09-04T20:37:41.526314Z","shell.execute_reply":"2024-09-04T20:37:53.177227Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step\nMAE Mean for total_calories --> 70.07911\nMAE Mean for total_mass --> 44.417343\nMAE Mean for total_fat --> 5.121333\nMAE Mean for total_carb --> 6.6875234\nMAE Mean for total_protein --> 7.219619\nTotal MAE --> 26.704985\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for now the best\nmodel = nutrition5k(version=\"v3\", loss=\"mae\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:37:53.179490Z","iopub.execute_input":"2024-09-04T20:37:53.180309Z","iopub.status.idle":"2024-09-04T20:37:55.144714Z","shell.execute_reply.started":"2024-09-04T20:37:53.180258Z","shell.execute_reply":"2024-09-04T20:37:55.143930Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\nhistory = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n                    validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:37:55.145840Z","iopub.execute_input":"2024-09-04T20:37:55.146166Z","iopub.status.idle":"2024-09-04T20:39:46.601931Z","shell.execute_reply.started":"2024-09-04T20:37:55.146134Z","shell.execute_reply":"2024-09-04T20:39:46.601010Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - loss: 60.7869 - mae: 60.7869 - val_loss: 43.8822 - val_mae: 43.8822\nEpoch 2/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 38.8948 - mae: 38.8948 - val_loss: 39.2042 - val_mae: 39.2042\nEpoch 3/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 36.7289 - mae: 36.7289 - val_loss: 35.9019 - val_mae: 35.9019\nEpoch 4/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 34.1670 - mae: 34.1670 - val_loss: 33.9516 - val_mae: 33.9516\nEpoch 5/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 31.7202 - mae: 31.7202 - val_loss: 33.7483 - val_mae: 33.7483\nEpoch 6/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 29.8645 - mae: 29.8645 - val_loss: 32.1478 - val_mae: 32.1478\nEpoch 7/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 28.5559 - mae: 28.5559 - val_loss: 30.6578 - val_mae: 30.6578\nEpoch 8/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 28.4404 - mae: 28.4404 - val_loss: 30.3967 - val_mae: 30.3967\nEpoch 9/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 26.7140 - mae: 26.7140 - val_loss: 29.6826 - val_mae: 29.6826\nEpoch 10/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 24.8791 - mae: 24.8791 - val_loss: 30.0457 - val_mae: 30.0457\nEpoch 11/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 23.6854 - mae: 23.6854 - val_loss: 30.3675 - val_mae: 30.3675\nEpoch 12/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 22.1027 - mae: 22.1027 - val_loss: 30.5975 - val_mae: 30.5975\nEpoch 13/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 21.3691 - mae: 21.3691 - val_loss: 32.6814 - val_mae: 32.6814\nEpoch 14/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 22.4635 - mae: 22.4635 - val_loss: 31.3004 - val_mae: 31.3004\n","output_type":"stream"}]},{"cell_type":"code","source":"xgboost_test(model, inputs=[rgb_imgs_train, rgb_imgs_validation, rgb_imgs_test],\n                          outputs=[rgb_imgs_metadata_train, rgb_imgs_metadata_validation, rgb_imgs_metadata_test])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:39:46.603394Z","iopub.execute_input":"2024-09-04T20:39:46.603710Z","iopub.status.idle":"2024-09-04T20:40:07.621729Z","shell.execute_reply.started":"2024-09-04T20:39:46.603677Z","shell.execute_reply":"2024-09-04T20:40:07.620905Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step\nValidation Mean Absolute Error of: 29.752090454101562\nMAE Mean for total_calories --> 69.40536\nMAE Mean for total_mass --> 48.741177\nMAE Mean for total_fat --> 5.389448\nMAE Mean for total_carb --> 7.7314973\nMAE Mean for total_protein --> 7.1848574\nTotal MAE --> 27.690468\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(model, rgb_imgs_test, rgb_imgs_metadata_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:40:07.623153Z","iopub.execute_input":"2024-09-04T20:40:07.624082Z","iopub.status.idle":"2024-09-04T20:40:15.379518Z","shell.execute_reply.started":"2024-09-04T20:40:07.624040Z","shell.execute_reply":"2024-09-04T20:40:15.378628Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 262ms/step\nMAE Mean for total_calories --> 70.35804\nMAE Mean for total_mass --> 47.477623\nMAE Mean for total_fat --> 5.6916804\nMAE Mean for total_carb --> 7.8741155\nMAE Mean for total_protein --> 7.565407\nTotal MAE --> 27.793375\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = nutrition5k(version=\"v2\", loss=\"mae\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:40:15.380839Z","iopub.execute_input":"2024-09-04T20:40:15.381262Z","iopub.status.idle":"2024-09-04T20:40:21.854201Z","shell.execute_reply.started":"2024-09-04T20:40:15.381217Z","shell.execute_reply":"2024-09-04T20:40:21.853065Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\nhistory = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n                    validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:40:21.855540Z","iopub.execute_input":"2024-09-04T20:40:21.855918Z","iopub.status.idle":"2024-09-04T20:46:43.088403Z","shell.execute_reply.started":"2024-09-04T20:40:21.855875Z","shell.execute_reply":"2024-09-04T20:46:43.087241Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 342ms/step - loss: 59.7897 - mae: 59.7897 - val_loss: 44.3012 - val_mae: 44.3012\nEpoch 2/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 127ms/step - loss: 42.6345 - mae: 42.6345 - val_loss: 39.6240 - val_mae: 39.6240\nEpoch 3/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 128ms/step - loss: 39.4358 - mae: 39.4358 - val_loss: 38.7455 - val_mae: 38.7455\nEpoch 4/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - loss: 38.0157 - mae: 38.0157 - val_loss: 36.9419 - val_mae: 36.9419\nEpoch 5/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - loss: 34.4632 - mae: 34.4632 - val_loss: 34.9269 - val_mae: 34.9269\nEpoch 6/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - loss: 31.3134 - mae: 31.3134 - val_loss: 35.2291 - val_mae: 35.2291\nEpoch 7/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 127ms/step - loss: 29.9227 - mae: 29.9227 - val_loss: 33.6384 - val_mae: 33.6384\nEpoch 8/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - loss: 30.9771 - mae: 30.9771 - val_loss: 34.0725 - val_mae: 34.0725\nEpoch 9/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 127ms/step - loss: 29.8395 - mae: 29.8395 - val_loss: 32.5360 - val_mae: 32.5360\nEpoch 10/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 27.9882 - mae: 27.9882 - val_loss: 36.2073 - val_mae: 36.2073\nEpoch 11/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - loss: 28.9466 - mae: 28.9466 - val_loss: 36.6139 - val_mae: 36.6139\nEpoch 12/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - loss: 30.2343 - mae: 30.2343 - val_loss: 33.4633 - val_mae: 33.4633\nEpoch 13/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 126ms/step - loss: 25.4534 - mae: 25.4534 - val_loss: 31.2304 - val_mae: 31.2304\nEpoch 14/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 25.5657 - mae: 25.5657 - val_loss: 36.8748 - val_mae: 36.8748\nEpoch 15/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 24.2181 - mae: 24.2181 - val_loss: 38.0754 - val_mae: 38.0754\nEpoch 16/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - loss: 24.5729 - mae: 24.5729 - val_loss: 36.6993 - val_mae: 36.6993\nEpoch 17/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 22.4878 - mae: 22.4878 - val_loss: 36.1408 - val_mae: 36.1408\nEpoch 18/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - loss: 22.2780 - mae: 22.2780 - val_loss: 33.2496 - val_mae: 33.2496\n","output_type":"stream"}]},{"cell_type":"code","source":"xgboost_test(model, inputs=[rgb_imgs_train, rgb_imgs_validation, rgb_imgs_test],\n                          outputs=[rgb_imgs_metadata_train, rgb_imgs_metadata_validation, rgb_imgs_metadata_test])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:46:43.095627Z","iopub.execute_input":"2024-09-04T20:46:43.095975Z","iopub.status.idle":"2024-09-04T20:47:46.647678Z","shell.execute_reply.started":"2024-09-04T20:46:43.095927Z","shell.execute_reply":"2024-09-04T20:47:46.646857Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 317ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step  \n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 586ms/step\nValidation Mean Absolute Error of: 32.047386169433594\nMAE Mean for total_calories --> 84.76781\nMAE Mean for total_mass --> 46.9249\nMAE Mean for total_fat --> 6.2950993\nMAE Mean for total_carb --> 9.108825\nMAE Mean for total_protein --> 8.083182\nTotal MAE --> 31.03596\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(model, rgb_imgs_test, rgb_imgs_metadata_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:47:46.651063Z","iopub.execute_input":"2024-09-04T20:47:46.653277Z","iopub.status.idle":"2024-09-04T20:48:11.395314Z","shell.execute_reply.started":"2024-09-04T20:47:46.653238Z","shell.execute_reply":"2024-09-04T20:48:11.394415Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 920ms/step\nMAE Mean for total_calories --> 81.144104\nMAE Mean for total_mass --> 45.9366\nMAE Mean for total_fat --> 6.168474\nMAE Mean for total_carb --> 8.63509\nMAE Mean for total_protein --> 8.1956835\nTotal MAE --> 30.016\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = nutrition5k(version=\"v3\", loss=\"custom\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:48:11.396530Z","iopub.execute_input":"2024-09-04T20:48:11.396850Z","iopub.status.idle":"2024-09-04T20:48:13.358722Z","shell.execute_reply.started":"2024-09-04T20:48:11.396816Z","shell.execute_reply":"2024-09-04T20:48:13.357905Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\n# , callbacks=callbacks\nhistory = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n                    validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:48:13.359916Z","iopub.execute_input":"2024-09-04T20:48:13.360227Z","iopub.status.idle":"2024-09-04T20:50:42.098589Z","shell.execute_reply.started":"2024-09-04T20:48:13.360194Z","shell.execute_reply":"2024-09-04T20:50:42.097507Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 120ms/step - loss: 307.3256 - mae: 66.7865 - val_loss: 191.3788 - val_mae: 42.6253\nEpoch 2/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 182.0703 - mae: 40.2895 - val_loss: 174.4297 - val_mae: 38.9102\nEpoch 3/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 169.7308 - mae: 37.6820 - val_loss: 170.8270 - val_mae: 38.1342\nEpoch 4/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 163.0605 - mae: 36.2184 - val_loss: 166.9398 - val_mae: 37.2663\nEpoch 5/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 156.8215 - mae: 34.8767 - val_loss: 162.4985 - val_mae: 36.3084\nEpoch 6/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 152.6192 - mae: 33.9845 - val_loss: 156.7360 - val_mae: 35.1330\nEpoch 7/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 144.9757 - mae: 32.3987 - val_loss: 153.4514 - val_mae: 34.4531\nEpoch 8/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 137.6816 - mae: 30.8969 - val_loss: 145.7282 - val_mae: 32.8235\nEpoch 9/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 130.7987 - mae: 29.4564 - val_loss: 147.1203 - val_mae: 33.0127\nEpoch 10/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 127.4673 - mae: 28.7570 - val_loss: 140.9169 - val_mae: 31.7142\nEpoch 11/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 120.7505 - mae: 27.3596 - val_loss: 137.9753 - val_mae: 31.0905\nEpoch 12/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 115.6519 - mae: 26.2809 - val_loss: 142.3712 - val_mae: 32.0400\nEpoch 13/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 110.1086 - mae: 25.0677 - val_loss: 138.0536 - val_mae: 31.1404\nEpoch 14/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 108.6072 - mae: 24.7590 - val_loss: 137.6172 - val_mae: 31.1816\nEpoch 15/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 105.5242 - mae: 24.0931 - val_loss: 130.4303 - val_mae: 29.5344\nEpoch 16/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 94.9180 - mae: 21.9037 - val_loss: 135.2174 - val_mae: 30.6064\nEpoch 17/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 92.4817 - mae: 21.3868 - val_loss: 137.8587 - val_mae: 31.0910\nEpoch 18/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 96.6028 - mae: 22.1691 - val_loss: 140.9247 - val_mae: 31.7581\nEpoch 19/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 90.7338 - mae: 20.9374 - val_loss: 152.1597 - val_mae: 34.4130\nEpoch 20/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 104.0068 - mae: 23.8426 - val_loss: 148.7253 - val_mae: 33.0254\n","output_type":"stream"}]},{"cell_type":"code","source":"xgboost_test(model, inputs=[rgb_imgs_train, rgb_imgs_validation, rgb_imgs_test],\n                          outputs=[rgb_imgs_metadata_train, rgb_imgs_metadata_validation, rgb_imgs_metadata_test])\n    \n    \n# # WITH PREVIOUS augmentation parameters\n# MAE Mean for total_calories --> 74.89289\n# MAE Mean for total_mass --> 46.198105\n# MAE Mean for total_fat --> 6.363183\n# MAE Mean for total_carb --> 8.111093\n# MAE Mean for total_protein --> 8.364978","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:50:42.105778Z","iopub.execute_input":"2024-09-04T20:50:42.106120Z","iopub.status.idle":"2024-09-04T20:51:03.028614Z","shell.execute_reply.started":"2024-09-04T20:50:42.106087Z","shell.execute_reply":"2024-09-04T20:51:03.027818Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 237ms/step\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step\nValidation Mean Absolute Error of: 28.59465980529785\nMAE Mean for total_calories --> 71.62666\nMAE Mean for total_mass --> 43.012768\nMAE Mean for total_fat --> 5.7270637\nMAE Mean for total_carb --> 8.468128\nMAE Mean for total_protein --> 7.6299496\nTotal MAE --> 27.292921\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(model, rgb_imgs_test, rgb_imgs_metadata_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:51:03.032104Z","iopub.execute_input":"2024-09-04T20:51:03.034039Z","iopub.status.idle":"2024-09-04T20:51:10.746516Z","shell.execute_reply.started":"2024-09-04T20:51:03.034000Z","shell.execute_reply":"2024-09-04T20:51:10.745471Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 258ms/step\nMAE Mean for total_calories --> 73.07089\nMAE Mean for total_mass --> 43.871315\nMAE Mean for total_fat --> 5.9916515\nMAE Mean for total_carb --> 9.520895\nMAE Mean for total_protein --> 8.655392\nTotal MAE --> 28.22203\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = nutrition5k(version=\"v2\", loss=\"geometric\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:51:10.747966Z","iopub.execute_input":"2024-09-04T20:51:10.748358Z","iopub.status.idle":"2024-09-04T20:51:15.358924Z","shell.execute_reply.started":"2024-09-04T20:51:10.748313Z","shell.execute_reply":"2024-09-04T20:51:15.358133Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\nhistory = model.fit(rgb_imgs_train, rgb_imgs_metadata_train, batch_size=batch_size, epochs=epochs, \n                    validation_data=(rgb_imgs_validation, rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:51:15.360303Z","iopub.execute_input":"2024-09-04T20:51:15.360686Z","iopub.status.idle":"2024-09-04T20:55:07.415823Z","shell.execute_reply.started":"2024-09-04T20:51:15.360635Z","shell.execute_reply":"2024-09-04T20:55:07.414977Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 303ms/step - loss: 33.3675 - mae: 81.3422 - val_loss: 22.2067 - val_mae: 40.3517\nEpoch 2/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 124ms/step - loss: 21.6599 - mae: 40.5549 - val_loss: 22.4934 - val_mae: 39.5939\nEpoch 3/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 128ms/step - loss: 20.1169 - mae: 37.1853 - val_loss: 21.1503 - val_mae: 37.9016\nEpoch 4/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - loss: 18.6299 - mae: 34.5089 - val_loss: 19.3087 - val_mae: 35.3803\nEpoch 5/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - loss: 17.7493 - mae: 32.9014 - val_loss: 19.2605 - val_mae: 34.5868\nEpoch 6/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 16.5758 - mae: 30.7786 - val_loss: 23.6901 - val_mae: 39.5986\nEpoch 7/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 17.1044 - mae: 32.1436 - val_loss: 22.0904 - val_mae: 38.7701\nEpoch 8/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 123ms/step - loss: 18.0398 - mae: 33.8901 - val_loss: 19.8919 - val_mae: 35.7311\nEpoch 9/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 15.2945 - mae: 28.2636 - val_loss: 19.3355 - val_mae: 35.1422\nEpoch 10/60\n\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 14.4648 - mae: 26.5301 - val_loss: 20.4281 - val_mae: 37.8379\n","output_type":"stream"}]},{"cell_type":"code","source":"xgboost_test(model, inputs=[rgb_imgs_train, rgb_imgs_validation, rgb_imgs_test],\n                          outputs=[rgb_imgs_metadata_train, rgb_imgs_metadata_validation, rgb_imgs_metadata_test])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:55:07.417356Z","iopub.execute_input":"2024-09-04T20:55:07.417659Z","iopub.status.idle":"2024-09-04T20:55:58.715021Z","shell.execute_reply.started":"2024-09-04T20:55:07.417627Z","shell.execute_reply":"2024-09-04T20:55:58.714240Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 311ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 744ms/step\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 448ms/step\nValidation Mean Absolute Error of: 31.747610092163086\nMAE Mean for total_calories --> 88.198006\nMAE Mean for total_mass --> 52.59832\nMAE Mean for total_fat --> 6.83967\nMAE Mean for total_carb --> 9.811279\nMAE Mean for total_protein --> 8.026792\nTotal MAE --> 33.094814\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(model, rgb_imgs_test, rgb_imgs_metadata_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:55:58.718350Z","iopub.execute_input":"2024-09-04T20:55:58.720692Z","iopub.status.idle":"2024-09-04T20:56:23.748702Z","shell.execute_reply.started":"2024-09-04T20:55:58.720653Z","shell.execute_reply":"2024-09-04T20:56:23.747792Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 984ms/step\nMAE Mean for total_calories --> 92.177124\nMAE Mean for total_mass --> 55.843803\nMAE Mean for total_fat --> 7.2581944\nMAE Mean for total_carb --> 9.134695\nMAE Mean for total_protein --> 8.742482\nTotal MAE --> 34.631264\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RGB-D model","metadata":{}},{"cell_type":"code","source":"class ConvolutionalAttentionBlock(layers.Layer):\n    def __init__(self, filters):\n        super(ConvolutionalAttentionBlock, self).__init__()\n        self.conv1x1_first = layers.Conv2D(filters, (1, 1), padding='same', activation=\"relu\")\n        self.bn_1x1 = layers.BatchNormalization()\n        self.relu_1x1 = layers.ReLU()\n        \n        self.conv3x3 = layers.Conv2D(filters, (3, 3), padding='same', activation=\"relu\")\n        self.bn_3x3 = layers.BatchNormalization()\n        self.relu_3x3 = layers.ReLU()\n        \n        self.conv1x1_second = layers.Conv2D(filters, (1, 1), padding='same')\n        self.sigmoid = layers.Activation('sigmoid')\n\n    # , inputs\n    def call(self, Ri, Di):\n#         # architecture\n#         Ri, Di = inputs\n        \n        # Element-wise addition of Ri and Di\n        combined = layers.Add()([Ri, Di])\n        \n        # Global Average Pooling (GAP) for channel attention\n        ca = layers.GlobalAveragePooling2D()(combined)\n        ca = layers.Reshape((1, 1, -1))(ca)\n        ca = self.conv1x1_first(ca)\n        ca = self.bn_1x1(ca)\n        ca = self.relu_1x1(ca)\n        ca = self.sigmoid(ca)\n        \n        # Channel-wise multiplication for channel attention\n        channel_attended_Ri = layers.Multiply()([Ri, ca])\n        channel_attended_Di = layers.Multiply()([Di, ca])\n        \n        # Mean along the channel dimension for spatial attention\n        mean_spatial = tf.reduce_mean(combined, axis=-1, keepdims=True)\n        \n        # Applying 3x3 Convolution for spatial attention\n        sa = self.conv3x3(mean_spatial)\n        sa = self.bn_3x3(sa)\n        sa = self.relu_3x3(sa)\n        sa = self.sigmoid(sa)\n        \n        # Spatial-wise multiplication for spatial attention\n        spatial_attended_Ri = layers.Multiply()([Ri, sa])\n        spatial_attended_Di = layers.Multiply()([Di, sa])\n        \n        # Concatenating enhanced features\n        enhanced_Ri = layers.Multiply()([channel_attended_Ri, spatial_attended_Ri])\n        enhanced_Di = layers.Multiply()([channel_attended_Di, spatial_attended_Di])\n        concatenated_features = layers.Concatenate()([enhanced_Ri, enhanced_Di])\n        \n        # Applying final 1x1 Convolution\n        output = self.conv1x1_second(concatenated_features)\n        \n        return output\n\n\nclass RGBDFusion(tf.keras.Model):\n    def __init__(self, use_midas=False):\n        super().__init__()\n        \n        self.use_midas = use_midas\n        \n        # architecture\n        \n        # rgb img\n        # 7x7 S2, 64 and 3x3 Max Pool S2 for rgb\n        self.first_conv_rgb = layers.Conv2D(64, (7,7), strides=(2,2))\n        self.first_maxpool_rgb = layers.MaxPooling2D((3,3), strides=(2,2))\n        \n        self.resnet_rgb = tf.keras.applications.ResNet101(include_top=False, weights='imagenet')\n        self.resnet_rgb.trainable = False\n        \n        # depth img\n        # 7x7 S2, 64 and 3x3 Max Pool S2 for rgb\n        self.first_conv_depth = layers.Conv2D(64, (7,7), strides=(2,2))\n        self.first_maxpool_depth = layers.MaxPooling2D((3,3), strides=(2,2))\n        \n        self.resnet_depth = tf.keras.applications.ResNet101(include_top=False, weights='imagenet')\n        self.resnet_depth.trainable = False\n        \n        # last union\n        self.resnet_union = tf.keras.applications.ResNet101(include_top=False, weights=\"imagenet\")\n        self.resnet_union.trainable = False\n        \n        self.cab = ConvolutionalAttentionBlock(filters=64)\n        self.gap = layers.GlobalAveragePooling2D()\n        \n        self.to_output = layers.Dense(5)\n        \n        \n    def call(self, inputs):\n        rgb_input, depth_input = inputs\n        \n        if self.use_midas:\n            model_type = \"DPT_Hybrid\"\n            midas = torch.hub.load(\"intel-isl/MiDaS\", model_type, pretrained=True)\n            midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n            transform = midas_transforms.dpt_transform\n            \n            print(rgb_input.__dir__())\n            print(type(rgb_input))\n            \n            depth_input = [transform(i) for i in rgb_input.numpy()]\n            depth_input = [midas(i) for i in depth_input]\n\n            \n        \n        \n        x_rgb = self.first_conv_rgb(rgb_input)\n        x_rgb = self.first_maxpool_rgb(x_rgb)\n        \n        x_depth = self.first_conv_depth(depth_input)\n        x_depth = self.first_maxpool_depth(x_depth)\n        \n    \n        resnet_layer_names = ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block23_out']\n\n        \n        rgb_features = []\n        depth_features = []\n        for layer_name in resnet_layer_names:\n            layer = self.resnet_rgb.get_layer(layer_name)\n            x_rgb = layer(x_rgb)\n            rgb_features.append(x_rgb)\n            \n            layer = self.resnet_depth.get_layer(layer_name)\n            x_depth = layer(x_depth)\n            depth_features.append(x_depth)\n        \n        \n        cab_outputs = [self.cab(r, d) for r, d in zip(rgb_features, depth_features)]\n        cab_outputs.insert(0, self.cab(x_rgb, x_depth))\n        \n        \n        layer = self.resnet_union.get_layer(resnet_layer_names[0])\n        output = layer(cab_outputs[0])\n        for cab_data, layer_name in zip(cab_outputs[1:], resnet_layer_names[1:]):\n            layer = self.resnet_union.get_layer(layer_name)\n            combined = layers.Add()([output, cab_data])\n            output = layer(combined)\n            \n        combined = layers.Add()([output, cab_outputs[-1]])\n        output = self.gap(combined)\n        \n        return self.to_output(output)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:23.750254Z","iopub.execute_input":"2024-09-04T20:56:23.750556Z","iopub.status.idle":"2024-09-04T20:56:23.776802Z","shell.execute_reply.started":"2024-09-04T20:56:23.750524Z","shell.execute_reply":"2024-09-04T20:56:23.775860Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"rgbd_fusion = RGBDFusion(use_midas=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:23.778155Z","iopub.execute_input":"2024-09-04T20:56:23.778595Z","iopub.status.idle":"2024-09-04T20:56:31.931100Z","shell.execute_reply.started":"2024-09-04T20:56:23.778552Z","shell.execute_reply":"2024-09-04T20:56:31.930252Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m171446536/171446536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = keras.optimizers.Adam()\n\n# \"mae\", custom_multitask_loss, geometric_mean_loss\nrgbd_fusion.compile(optimizer=optimizer, loss=geometric_mean_loss, metrics=[\"mae\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:31.932182Z","iopub.execute_input":"2024-09-04T20:56:31.932472Z","iopub.status.idle":"2024-09-04T20:56:31.945203Z","shell.execute_reply.started":"2024-09-04T20:56:31.932441Z","shell.execute_reply":"2024-09-04T20:56:31.944490Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"callbacks = get_callbacks()\n\nhistory = rgbd_fusion.fit([rgb_imgs_train.astype(\"float32\"), depth_imgs_train.astype(\"float32\")], rgb_imgs_metadata_train, \n                          batch_size=batch_size, epochs=epochs, \n                          validation_data=([rgb_imgs_validation.astype(\"float32\"), depth_imgs_validation.astype(\"float32\")], \n                                           rgb_imgs_metadata_validation), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:31.946491Z","iopub.execute_input":"2024-09-04T20:56:31.946839Z","iopub.status.idle":"2024-09-04T20:56:55.456915Z","shell.execute_reply.started":"2024-09-04T20:56:31.946805Z","shell.execute_reply":"2024-09-04T20:56:55.455495Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/60\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_base_resnet50_384 to current vit_base_r50_s16_384.orig_in21k_ft_in1k.\n  model = create_fn(\nDownloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_hybrid_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_hybrid_384.pt\n100%|██████████| 470M/470M [00:01<00:00, 373MB/s] \n\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"ind_sample = 1\n\nprint(rgbd_fusion.predict([np.array([rgb_imgs_test[ind_sample]]).astype(\"float32\"),\n                           np.array([depth_imgs_test[ind_sample]]).astype(\"float32\")]))\nprint(rgb_imgs_metadata_test[ind_sample])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:55.458041Z","iopub.status.idle":"2024-09-04T20:56:55.458446Z","shell.execute_reply.started":"2024-09-04T20:56:55.458223Z","shell.execute_reply":"2024-09-04T20:56:55.458242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predicted = rgbd_fusion.predict([rgb_imgs_test.astype(\"float32\"), depth_imgs_test.astype(\"float32\")])","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:55.460029Z","iopub.status.idle":"2024-09-04T20:56:55.460406Z","shell.execute_reply.started":"2024-09-04T20:56:55.460224Z","shell.execute_reply":"2024-09-04T20:56:55.460243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_errors = np.abs(test_predicted - rgb_imgs_metadata_test)\n\nfor val_name, val in zip(real_column_names[1:], np.mean(test_errors, axis=0)):\n    print(\"MAE Mean for\", val_name, '-->', val)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:55.461787Z","iopub.status.idle":"2024-09-04T20:56:55.462154Z","shell.execute_reply.started":"2024-09-04T20:56:55.461969Z","shell.execute_reply":"2024-09-04T20:56:55.461995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_type = \"DPT_Hybrid\"\nmidas = torch.hub.load(\"intel-isl/MiDaS\", model_type, pretrained=True)\nmidas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\ntransform = midas_transforms.dpt_transform\n\n[midas(transform(np.array(i.tolist()))) for i in rgb_imgs_train[:1000]]\n\n# depth_input = [transform(i) for i in .numpy()]\n# depth_input = [midas(i) for i in depth_input]","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:55.463329Z","iopub.status.idle":"2024-09-04T20:56:55.463656Z","shell.execute_reply.started":"2024-09-04T20:56:55.463491Z","shell.execute_reply":"2024-09-04T20:56:55.463508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ViT Regression","metadata":{}},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# from torch.utils.data import DataLoader, Dataset\n# import timm\n\n# # Define a sample dataset\n# class RegressionDataset(Dataset):\n#     def __init__(self, images, targets):\n#         self.images = images  # List of image tensors\n#         self.targets = targets  # List of target values\n\n#     def __len__(self):\n#         return len(self.images)\n\n#     def __getitem__(self, idx):\n#         image = self.images[idx]\n#         target = self.targets[idx]\n#         return image, target\n\n# rgb_imgs_train = rgb_imgs_train.reshape(len(rgb_imgs_train), 3, 224, 224)\n# rgb_imgs_test = rgb_imgs_test.reshape(len(rgb_imgs_test), 3, 224, 224)\n# rgb_imgs_validation = rgb_imgs_validation.reshape(len(rgb_imgs_validation), 3, 224, 224)\n\n# # Create the dataset and dataloader\n# train_dataset = RegressionDataset(rgb_imgs_train, rgb_imgs_metadata_train)\n# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\n# # Load a pre-trained ViT model from timm\n# model = timm.create_model('vit_base_patch16_224', pretrained=True)\n\n# # Modify the model's head for regression\n# num_features = model.head.in_features\n# model.head = nn.Linear(num_features, 5)  # Change the output layer to a single neuron for regression\n\n# # # Move model to GPU if available\n# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# # model = model.to(device)\n\n# # Define loss function and optimizer\n# criterion = nn.MSELoss()  # Mean Squared Error for regression\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Training loop\n# num_epochs = 10\n# for epoch in range(num_epochs):\n#     model.train()\n#     running_loss = 0.0\n#     for images, targets in train_loader:\n#         images = images#.to(device)\n#         targets = targets#.to(device)\n\n#         # Forward pass\n#         outputs = model(images)\n#         loss = criterion(outputs, targets)\n\n#         # Backward pass and optimization\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         running_loss += loss.item()\n\n#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# print(\"Training complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:55.465239Z","iopub.status.idle":"2024-09-04T20:56:55.465569Z","shell.execute_reply.started":"2024-09-04T20:56:55.465399Z","shell.execute_reply":"2024-09-04T20:56:55.465416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_predicted = model.predict(rgb_imgs_test)\n\n# test_errors = np.abs(test_predicted - rgb_imgs_metadata_test)\n\n# for val_name, val in zip(real_column_names[1:], np.mean(test_errors, axis=0)):\n#     print(\"MAE Mean for\", val_name, '-->', val)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T20:56:55.466768Z","iopub.status.idle":"2024-09-04T20:56:55.467269Z","shell.execute_reply.started":"2024-09-04T20:56:55.467015Z","shell.execute_reply":"2024-09-04T20:56:55.467040Z"},"trusted":true},"execution_count":null,"outputs":[]}]}